---
title: ICML 2017
layout: post
tags: 
local: 2017-08-06-ICML-2017
---

This is the first ever academic conference that I'm attending. I paid for it out
of my own pocket because I wanted to experience first hand what an academic
conference is like.

# Day 1 - Tutorials

There were 9 different tutorials at 3 different locations today. You could only
choose 3 to go for. Selecting tutorials are a tough choice. Going for all would
be optimal. In fact, going for every single talk would be great! However, that
would mean that the conference would span a month or more. Well, I guess it's
structured this way because not everyone can master everything. There will
come a point in time where it's beyond the capacity of a human to be well versed
in so many domains. 

## Interpretable Machine Learning

I was expecting more of methods that exactly show us how to interpret a deep
learning model. Some introductions to papers in this area were made but I've
seen them previously. Other than that, I got the idea that it's more of
formalizing exactly what interpretability is. I think this is a nascent idea and 
definitely very important in the field of Machine Learning (hardcore theory
people definitely think otherwise). I'm always of the idea that diversity of
ideas are important and everyone will play a small part in advancing the field
and everything will somehow converge eventually. Interpretability is important
for practical users; formal proofs are important for academic rigour and
potentially practical use (if they exist).

## Recent Advances in Stochastic Convex and Non-Convex Optimization

Allen Zhu is an incredible speaker. He's got a really impressive CV and is
extremely technical but can bring the talk down to a level where most can
understand (I think?). I don't claim to understand everything fully, but I
thought I could at least follow most of it.

I was introduced to primal, primal-dual, and dual forms of optimization
functions. This was totally new to me. I have no idea how these forms work and I
should really look into that if I intend to get a stronger foundation in
optimization. I was also introduced to the ideas of coordinate descent and
mirror descent. I think all these theories are extremely interesting (like how
coordinate descent guarantees a correct step). 

What struck me the most was when he said that momentum fails for SGD and SVRG.
He mentioned this in the context of convex optimization and offline learning.
Empirically, they work very well on almost all deep learning problems (which is
non-convex). So how can he say that it fails? My interpretation would be that
he's looking at it from a very strict optimization stand point of reaching
global minima. In that perspective, momentum is definitely worse as the
mini-batch gradient has high variance and taking momentum of a wrong gradient
can't be good. When we put this in the framework of deep learning, it starts to
make sense because there could be multiple local minima (which are all very
good) and saddle points (which you could escape from with SGD naturally). After
sitting through this lecture, **I'm really interested to know more about
optimization and formal theories of deep learning.**

## Sequence to Sequence Networks

This is something that has been really popular in recent times. I've glanced
through some papers on it. I'd really love to try an implementation of this on a
problem.

Oriol and Navdeep did a great job in introducing the various applications and
state-of-the-art methods and for me, what interests me the most would be
attention. **I'd like to learn more about how attention methods
work.**
